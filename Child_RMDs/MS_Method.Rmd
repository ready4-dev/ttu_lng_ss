---
title: "MS_Method"
author: "Matthew Hamilton"
date: "13/10/2020"
output:
  bookdown::pdf_document2: default
  html_document: default
  pdf_document: default
---
## Sample and setting
<!-- Add details on sample and setting (including data collection proceedures). -->

## Measures
Data was collected on utility weights, `r get_nbr_of_predrs(results_ls)` candidate predictors of utility weights and descriptive population characteristics. 

### Utility weights
Utility weights were assessed using the `r get_hlth_utl_nm(results_ls)` multi-attribute utility instrument.

### Candidate predictor`r ifelse(get_nbr_of_predrs(results_ls, as_words_1L_lgl = F)>1,"s","")`
Data from `r get_nbr_of_predrs(results_ls)` measure`r ifelse(get_nbr_of_predrs(results_ls, as_words_1L_lgl = F)>1,"s","")` of `r  get_nbr_of_predrs_by_ctg(results_ls)` were used as `r ifelse(get_nbr_of_predrs(results_ls, as_words_1L_lgl = F)>1,"","a ")`candidate predictor`r ifelse(get_nbr_of_predrs(results_ls, as_words_1L_lgl = F)>1,"s","")` to construct TTU models. 

`r get_predrs_by_ctg(results_ls, long_desc_1L_lgl = T) %>% paste0(collapse=" ")`

### Population characteristics
Population characteristic data were `r get_popl_descvs(results_ls)`.

## Statistical analysis
We applied a generalised form of the transfer to utility analysis algorithm developed by Hamilton, Gao and colleagues [@HamiltonGao2021]. Basic descriptive statistics were used to characterise the cohort in terms of baseline population variables. Pearsonâ€™s Product Moment Correlations (*r*) were used to determine the relationships between candidate predictors and the `r get_hlth_utl_nm(results_ls)` utility score.

### TTU regression models 
We compared predictive performance of a range of models predicting `r get_hlth_utl_nm(results_ls)` utility scores using the candidate predictor that had the highest Pearson correlation coefficient with utility scores. The models compared include `r get_mdl_cmprsns(results_ls, describe_1L_lgl = F)`. `r get_mdl_cmprsns(results_ls)`. Ten-fold cross-validation was used to compare model fitting using training datasets and predictive ability using testing datasets using three indicators including R^2^, root mean square error (RMSE) and mean absolute error (MAE)  [@RN20; @RN19].

To evaluate whether candidate predictors could independently predict utility scores, we established multivariate prediction models using baseline data with the candidate predictor and a range of other risk factors including `r results_ls$candiate_covars_chr %>% paste0(collapse = ", ") %>% stringi::stri_replace_last_fixed(","," and") %>% tolower()` .

### Candidate predictor comparison
We compared the usefulness of the candidate predictors by using a random forest model including all `r results_ls$study_descs_ls$predr_ctgs_ls %>% purrr::map_int(~length(.x)) %>% sum() %>% xfun::numbers_to_words()` candidate predictors and by evaluating the independent predictive ability of different candidate predictors using 10-fold cross-validation. 

### Longitudinal transfer to utility models
We next established longitudinal models using generalised linear mixed- effect models (GLMM) and Linear mixed effect model (LMM) that included both the baseline and follow-up data. Model fitting was evaluated using Bayesian R^2^ [@RN21].

`r ifelse(is.null(results_ls$secondary_chr),"","### Secondary analyses")`
`r ifelse(is.null(results_ls$secondary_chr),"",results_ls$secondary_chr[1])`

### Software
We undertook all our analyses using  ***R*** `r results_ls$r_version_1L_chr` [@RCitation] using the TTU package [@TTUPackage]. 
